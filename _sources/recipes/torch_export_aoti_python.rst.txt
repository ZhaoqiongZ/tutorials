
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "recipes/torch_export_aoti_python.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_recipes_torch_export_aoti_python.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_recipes_torch_export_aoti_python.py:


.. meta::
   :description: An end-to-end example of how to use AOTInductor for Python runtime.
   :keywords: torch.export, AOTInductor, torch._inductor.aot_compile, torch._export.aot_load

``torch.export`` AOTInductor Tutorial for Python runtime (Beta)
===============================================================
**Author:** Ankith Gunapal, Bin Bao, Angela Yi

.. GENERATED FROM PYTHON SOURCE LINES 14-34

.. warning::

    ``torch._inductor.aot_compile`` and ``torch._export.aot_load`` are in Beta status and are subject to backwards compatibility
    breaking changes. This tutorial provides an example of how to use these APIs for model deployment using Python runtime.

It has been shown `previously <https://pytorch.org/docs/stable/torch.compiler_aot_inductor.html#>`__ how AOTInductor can be used 
to do Ahead-of-Time compilation of PyTorch exported models by creating
a shared library that can be run in a non-Python environment.


In this tutorial, you will learn an end-to-end example of how to use AOTInductor for Python runtime.
We will look at how  to use :func:`torch._inductor.aot_compile` along with :func:`torch.export.export` to generate a 
shared library. Additionally, we will examine how to execute the shared library in Python runtime using :func:`torch._export.aot_load`.
You will learn about the speed up seen in the first inference time using AOTInductor, especially when using 
``max-autotune`` mode which can take some time to execute.

**Contents**

.. contents::
    :local:

.. GENERATED FROM PYTHON SOURCE LINES 37-42

Prerequisites
-------------
* PyTorch 2.4 or later
* Basic understanding of ``torch.export`` and AOTInductor
* Complete the `AOTInductor: Ahead-Of-Time Compilation for Torch.Export-ed Models <https://pytorch.org/docs/stable/torch.compiler_aot_inductor.html#>`_ tutorial

.. GENERATED FROM PYTHON SOURCE LINES 44-50

What you will learn
----------------------
* How to use AOTInductor for python runtime.
* How  to use :func:`torch._inductor.aot_compile` along with :func:`torch.export.export` to generate a shared library
* How to run a shared library in Python runtime using :func:`torch._export.aot_load`.
* When do you use AOTInductor for python runtime

.. GENERATED FROM PYTHON SOURCE LINES 52-66

Model Compilation
-----------------

We will use the TorchVision pretrained `ResNet18` model and TorchInductor on the 
exported PyTorch program using :func:`torch._inductor.aot_compile`.

.. note::

      This API also supports :func:`torch.compile` options like ``mode``
      This means that if used on a CUDA enabled device, you can, for example, set ``"max_autotune": True``
      which leverages Triton based matrix multiplications & convolutions, and enables CUDA graphs by default.

We also specify ``dynamic_shapes`` for the batch dimension. In this example, ``min=2`` is not a bug and is 
explained in `The 0/1 Specialization Problem <https://docs.google.com/document/d/16VPOa3d-Liikf48teAOmxLc92rgvJdfosIy-yoT38Io/edit?fbclid=IwAR3HNwmmexcitV0pbZm_x1a4ykdXZ9th_eJWK-3hBtVgKnrkmemz6Pm5jRQ#heading=h.ez923tomjvyk>`__

.. GENERATED FROM PYTHON SOURCE LINES 66-106

.. code-block:: default



    import os
    import torch
    from torchvision.models import ResNet18_Weights, resnet18

    model = resnet18(weights=ResNet18_Weights.DEFAULT)
    model.eval()

    with torch.inference_mode():

        # Specify the generated shared library path
        aot_compile_options = {
                "aot_inductor.output_path": os.path.join(os.getcwd(), "resnet18_pt2.so"),
        }
        if torch.cuda.is_available():
            device = "cuda"
            aot_compile_options.update({"max_autotune": True})
        else:
            device = "cpu"

        model = model.to(device=device)
        example_inputs = (torch.randn(2, 3, 224, 224, device=device),)

        # min=2 is not a bug and is explained in the 0/1 Specialization Problem
        batch_dim = torch.export.Dim("batch", min=2, max=32)
        exported_program = torch.export.export(
            model,
            example_inputs,
            # Specify the first dimension of the input x as dynamic
            dynamic_shapes={"x": {0: batch_dim}},
        )
        so_path = torch._inductor.aot_compile(
            exported_program.module(),
            example_inputs,
            # Specify the generated shared library path
            options=aot_compile_options
        )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /var/lib/ci-user/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth

      0%|          | 0.00/44.7M [00:00<?, ?B/s]
     94%|#########4| 42.0M/44.7M [00:00<00:00, 440MB/s]    100%|##########| 44.7M/44.7M [00:00<00:00, 439MB/s]
    AUTOTUNE convolution(2x3x224x224, 64x3x7x7)
      convolution 0.0463 ms 100.0% 
      triton_convolution2d_0 0.1038 ms 44.7% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=7, KERNEL_W=7, PADDING_H=3, PADDING_W=3, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_4 0.1064 ms 43.5% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=7, KERNEL_W=7, PADDING_H=3, PADDING_W=3, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_3 0.1274 ms 36.4% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, GROUPS=1, KERNEL_H=7, KERNEL_W=7, PADDING_H=3, PADDING_W=3, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_1 0.1404 ms 33.0% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=7, KERNEL_W=7, PADDING_H=3, PADDING_W=3, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_5 0.1868 ms 24.8% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=7, KERNEL_W=7, PADDING_H=3, PADDING_W=3, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_2 0.2195 ms 21.1% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=7, KERNEL_W=7, PADDING_H=3, PADDING_W=3, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=1, num_warps=8
    SingleProcess AUTOTUNE benchmarking takes 0.7460 seconds and 0.0069 seconds precompiling
    AUTOTUNE convolution(2x64x56x56, 64x64x3x3)
      convolution 0.0445 ms 100.0% 
      triton_convolution2d_6 0.0743 ms 59.9% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_9 0.0751 ms 59.2% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_12 0.0775 ms 57.4% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_10 0.0839 ms 53.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_11 0.0849 ms 52.4% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_7 0.1007 ms 44.2% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_8 0.1420 ms 31.3% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=1, num_warps=8
    SingleProcess AUTOTUNE benchmarking takes 0.9544 seconds and 0.0005 seconds precompiling
    AUTOTUNE convolution(2x64x56x56, 128x64x3x3)
      convolution 0.0342 ms 100.0% 
      triton_convolution2d_38 0.0630 ms 54.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_40 0.0817 ms 41.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_34 0.0862 ms 39.7% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_39 0.0916 ms 37.4% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_37 0.1070 ms 32.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_35 0.1103 ms 31.0% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_36 0.3060 ms 11.2% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=1, num_warps=8
    SingleProcess AUTOTUNE benchmarking takes 0.9641 seconds and 0.0005 seconds precompiling
    AUTOTUNE convolution(2x64x56x56, 128x64x1x1)
      triton_convolution2d_52 0.0111 ms 100.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      triton_convolution2d_53 0.0123 ms 90.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_48 0.0126 ms 87.8% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      convolution 0.0133 ms 83.2% 
      triton_convolution2d_54 0.0154 ms 71.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_51 0.0155 ms 71.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_49 0.0156 ms 71.0% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      triton_convolution2d_50 0.0457 ms 24.2% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=1, num_warps=8
    SingleProcess AUTOTUNE benchmarking takes 0.9593 seconds and 0.0005 seconds precompiling
    AUTOTUNE convolution(2x128x28x28, 128x128x3x3)
      convolution 0.0436 ms 100.0% 
      triton_convolution2d_59 0.1162 ms 37.5% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_61 0.1359 ms 32.1% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_55 0.1656 ms 26.3% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_60 0.1756 ms 24.8% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_56 0.1902 ms 22.9% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_58 0.1950 ms 22.4% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_57 0.2655 ms 16.4% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=1, num_warps=8
    SingleProcess AUTOTUNE benchmarking takes 0.9540 seconds and 0.0005 seconds precompiling
    AUTOTUNE convolution(2x128x28x28, 256x128x3x3)
      convolution 0.0374 ms 100.0% 
      triton_convolution2d_73 0.0986 ms 38.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_75 0.1590 ms 23.5% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_72 0.2024 ms 18.5% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_70 0.2149 ms 17.4% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_71 0.2651 ms 14.1% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=1, num_warps=8
      triton_convolution2d_74 0.2845 ms 13.2% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_69 0.3376 ms 11.1% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 0.9691 seconds and 0.0005 seconds precompiling
    AUTOTUNE convolution(2x128x28x28, 256x128x1x1)
      triton_convolution2d_87 0.0122 ms 100.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      convolution 0.0205 ms 59.7% 
      triton_convolution2d_86 0.0211 ms 57.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_88 0.0219 ms 55.8% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_89 0.0227 ms 53.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_85 0.0327 ms 37.4% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=1024, BLOCK_N=16, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=1, num_warps=8
      triton_convolution2d_83 0.0492 ms 24.9% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      triton_convolution2d_84 0.0583 ms 21.0% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 0.9980 seconds and 0.0004 seconds precompiling
    AUTOTUNE convolution(2x256x14x14, 256x256x3x3)
      convolution 0.0533 ms 100.0% 
      triton_convolution2d_94 0.1849 ms 28.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_92 0.2605 ms 20.5% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=512, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=1, num_warps=8
      triton_convolution2d_96 0.2628 ms 20.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_91 0.3713 ms 14.4% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_93 0.3732 ms 14.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_95 0.5461 ms 9.8% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_90 0.6536 ms 8.2% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 0.9452 seconds and 0.0006 seconds precompiling
    AUTOTUNE convolution(2x256x14x14, 512x256x3x3)
      convolution 0.0529 ms 100.0% 
      triton_convolution2d_108 0.1923 ms 27.5% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_106 0.2817 ms 18.8% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=512, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=1, num_warps=8
      triton_convolution2d_110 0.2934 ms 18.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_105 0.3836 ms 13.8% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_107 0.3895 ms 13.6% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_109 0.5596 ms 9.5% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_104 0.6862 ms 7.7% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=2, STRIDE_W=2, UNROLL=False, num_stages=2, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 0.9516 seconds and 0.0005 seconds precompiling
    AUTOTUNE convolution(2x256x14x14, 512x256x1x1)
      triton_convolution2d_122 0.0178 ms 100.0% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      convolution 0.0255 ms 69.7% 
      triton_convolution2d_120 0.0335 ms 53.1% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=512, BLOCK_N=16, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=1, num_warps=8
      triton_convolution2d_124 0.0340 ms 52.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_123 0.0353 ms 50.4% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_121 0.0478 ms 37.2% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=8
      triton_convolution2d_118 0.1782 ms 10.0% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
      triton_convolution2d_119 0.1828 ms 9.7% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=256, BLOCK_N=64, GROUPS=1, KERNEL_H=1, KERNEL_W=1, PADDING_H=0, PADDING_W=0, STRIDE_H=2, STRIDE_W=2, UNROLL=True, num_stages=2, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 0.9994 seconds and 0.0006 seconds precompiling
    AUTOTUNE convolution(2x512x7x7, 512x512x3x3)
      convolution 0.0860 ms 100.0% 
      triton_convolution2d_127 0.2785 ms 30.9% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=1, num_warps=8
      triton_convolution2d_129 0.3604 ms 23.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_131 0.4232 ms 20.3% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_126 0.4849 ms 17.7% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=64, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
      triton_convolution2d_128 0.7227 ms 11.9% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_130 1.1001 ms 7.8% ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=8
      triton_convolution2d_125 1.4555 ms 5.9% ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=256, GROUPS=1, KERNEL_H=3, KERNEL_W=3, PADDING_H=1, PADDING_W=1, STRIDE_H=1, STRIDE_W=1, UNROLL=False, num_stages=2, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 0.9592 seconds and 0.0006 seconds precompiling
    AUTOTUNE addmm(2x1000, 2x512, 512x1000)
      addmm 0.0155 ms 100.0% 
      triton_mm_142 0.0220 ms 70.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
      triton_mm_152 0.0302 ms 51.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
      triton_mm_153 0.0306 ms 50.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
      triton_mm_141 0.0308 ms 50.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
      triton_mm_146 0.0313 ms 49.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
      triton_mm_139 0.0349 ms 44.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
      triton_mm_145 0.0372 ms 41.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
      triton_mm_144 0.0461 ms 33.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
      triton_mm_148 0.0499 ms 31.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
    SingleProcess AUTOTUNE benchmarking takes 1.8124 seconds and 0.0020 seconds precompiling




.. GENERATED FROM PYTHON SOURCE LINES 107-118

Model Inference in Python
-------------------------

Typically, the shared object generated above is used in a non-Python environment. In PyTorch 2.3, 
we added a new API called :func:`torch._export.aot_load` to load the shared library in the Python runtime.
The API follows a structure similar to the :func:`torch.jit.load` API . You need to specify the path 
of the shared library and the device where it should be loaded.

.. note::
     In the example above, we specified ``batch_size=1`` for inference and  it still functions correctly even though we specified ``min=2`` in 
     :func:`torch.export.export`.

.. GENERATED FROM PYTHON SOURCE LINES 118-132

.. code-block:: default



    import os
    import torch

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_so_path = os.path.join(os.getcwd(), "resnet18_pt2.so")

    model = torch._export.aot_load(model_so_path, device)
    example_inputs = (torch.randn(1, 3, 224, 224, device=device),)

    with torch.inference_mode():
        output = model(example_inputs)








.. GENERATED FROM PYTHON SOURCE LINES 133-154

When to use AOTInductor for Python Runtime
------------------------------------------

One of the requirements for using AOTInductor is that the model shouldn't have any graph breaks.
Once this requirement is met, the primary use case for using AOTInductor Python Runtime is for
model deployment using Python.
There are mainly two reasons why you would use AOTInductor Python Runtime:

-  ``torch._inductor.aot_compile`` generates a shared library. This is useful for model
   versioning for deployments and tracking model performance over time.
-  With :func:`torch.compile` being a JIT compiler, there is a warmup
   cost associated with the first compilation. Your deployment needs to account for the
   compilation time taken for the first inference. With AOTInductor, the compilation is
   done offline using ``torch.export.export`` & ``torch._indutor.aot_compile``. The deployment
   would only load the shared library using ``torch._export.aot_load`` and run inference.


The section below shows the speedup achieved with AOTInductor for first inference

We define a utility function ``timed`` to measure the time taken for inference


.. GENERATED FROM PYTHON SOURCE LINES 154-183

.. code-block:: default


    import time
    def timed(fn):
        # Returns the result of running `fn()` and the time it took for `fn()` to run,
        # in seconds. We use CUDA events and synchronization for accurate
        # measurement on CUDA enabled devices.
        if torch.cuda.is_available():
            start = torch.cuda.Event(enable_timing=True)
            end = torch.cuda.Event(enable_timing=True)
            start.record()
        else:
            start = time.time()

        result = fn()
        if torch.cuda.is_available():
            end.record()
            torch.cuda.synchronize()
        else:
            end = time.time()

        # Measure time taken to execute the function in miliseconds
        if torch.cuda.is_available():
            duration = start.elapsed_time(end)
        else:
            duration = (end - start) * 1000

        return result, duration









.. GENERATED FROM PYTHON SOURCE LINES 184-185

Lets measure the time for first inference using AOTInductor

.. GENERATED FROM PYTHON SOURCE LINES 185-196

.. code-block:: default


    torch._dynamo.reset()

    model = torch._export.aot_load(model_so_path, device)
    example_inputs = (torch.randn(1, 3, 224, 224, device=device),)

    with torch.inference_mode():
        _, time_taken = timed(lambda: model(example_inputs))
        print(f"Time taken for first inference for AOTInductor is {time_taken:.2f} ms")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Time taken for first inference for AOTInductor is 2.92 ms




.. GENERATED FROM PYTHON SOURCE LINES 197-198

Lets measure the time for first inference using ``torch.compile``

.. GENERATED FROM PYTHON SOURCE LINES 198-211

.. code-block:: default


    torch._dynamo.reset()

    model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)
    model.eval()

    model = torch.compile(model)
    example_inputs = torch.randn(1, 3, 224, 224, device=device)

    with torch.inference_mode():
        _, time_taken = timed(lambda: model(example_inputs))
        print(f"Time taken for first inference for torch.compile is {time_taken:.2f} ms")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Time taken for first inference for torch.compile is 6823.93 ms




.. GENERATED FROM PYTHON SOURCE LINES 212-214

We see that there is a drastic speedup in first inference time using AOTInductor compared
to ``torch.compile``

.. GENERATED FROM PYTHON SOURCE LINES 216-225

Conclusion
----------

In this recipe, we have learned how to effectively use the AOTInductor for Python runtime by 
compiling and loading a pretrained ``ResNet18`` model using the ``torch._inductor.aot_compile``
and ``torch._export.aot_load`` APIs. This process demonstrates the practical application of 
generating a shared library and running it within a Python environment, even with dynamic shape
considerations and device-specific optimizations. We also looked at the advantage of using 
AOTInductor in model deployments, with regards to speed up in first inference time.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  26.063 seconds)


.. _sphx_glr_download_recipes_torch_export_aoti_python.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: torch_export_aoti_python.py <torch_export_aoti_python.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: torch_export_aoti_python.ipynb <torch_export_aoti_python.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
